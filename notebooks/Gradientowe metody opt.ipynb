{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os \n",
    "from functools import partial\n",
    "import scipy\n",
    "from scipy.optimize import fmin\n",
    "DATA_DIR = r\"C:\\Users\\julia\\VSCode\\MSiD\\data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1\n",
    "W metodzie stałokrokowej nie mamy gwarancji osiągnięcia minimum, gdyż przy stałym kroku możemy nawet przeskoczyć minimum lokalne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(func, gradient, learning_rate, start_point, stop_condition, write_to=None):\n",
    "    current_point = start_point\n",
    "    i = 1\n",
    "    while True:\n",
    "        print(f\"ITERATION {i}\", file=write_to)\n",
    "        gradient_value = gradient(current_point)\n",
    "        print(f\"\\tgradient_value = {gradient_value}\", file=write_to)\n",
    "        step_size = learning_rate * gradient_value\n",
    "        print(f\"\\tstep_size = {step_size}\", file=write_to)\n",
    "        next_point = current_point - step_size \n",
    "        print(f\"\\tnext_point = {next_point}\", file=write_to)\n",
    "        print(f\"\\tf({next_point}) = {func(next_point)}\", file=write_to)\n",
    "\n",
    "        if stop_condition(current_point, next_point, write_to=write_to):\n",
    "            print(f\"Reached stop condition at {next_point}, value = {func(next_point)}\", file=write_to)\n",
    "            break \n",
    "        i += 1\n",
    "        current_point = next_point\n",
    "    \n",
    "\n",
    "    return current_point\n",
    "\n",
    "\n",
    "def func(X):\n",
    "    return np.sum(X ** 2)\n",
    "\n",
    "def gradient(X):\n",
    "    return X * 2\n",
    "\n",
    "def L1_norm(X):\n",
    "    return np.sum(np.abs(X))\n",
    "\n",
    "def L2_norm(X):\n",
    "    return np.sqrt(np.sum(X ** 2))\n",
    "\n",
    "def stop(current_point, next_point, error, write_to=None):\n",
    "    computed = L2_norm(current_point - next_point)\n",
    "    print(f\"L2 = {computed}\", file=write_to) \n",
    "    return computed < error \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f([0.0065536 0.0065536]) = 8.589934592000008e-05\n"
     ]
    }
   ],
   "source": [
    "h_i = 0.3\n",
    "x_start = np.array([4, 4])\n",
    "with open(os.path.join(DATA_DIR, \"ex1.txt\"), mode='w') as f:\n",
    "    result = steepest_descent(func, gradient, h_i, x_start, partial(stop, error=0.01), write_to=f)\n",
    "    print(f\"f({result}) = {func(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.array([3, 4])\n",
    "v2 = np.array([1, 1])\n",
    "\n",
    "# Subtraction is element-wise\n",
    "v1 - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 44\n",
      "         Function evaluations: 80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.503461544006107e-10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy_min = fmin(func, x0=x_start)\n",
    "func(scipy_min)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2\n",
    "Minimum tej funkcji znajduje się w punkcie (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f([0.43228954 0.07528693]) = 0.35342448875174604\n"
     ]
    }
   ],
   "source": [
    "def func(X):\n",
    "    return 2.5 * (X[0] ** 2 - X[1]) ** 2 + (1 - X[0]) ** 2\n",
    "\n",
    "def gradient(X):\n",
    "    return np.array([10 * X[0] ** 3 - 10 * X[0] * X[1] + 2 * X[0] - 2, \n",
    "                     -5 * (X[0] ** 2 - X[1])])\n",
    "\n",
    "h_i = 0.1\n",
    "x_start = np.array([-0.5, 1])\n",
    "with open(os.path.join(DATA_DIR, \"ex2.txt\"), mode='w') as f:\n",
    "    result = steepest_descent(func, gradient, h_i, x_start, partial(stop, error=0.1), write_to=f)\n",
    "    print(f\"f({result}) = {func(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f([0.89834828 0.78934951]) = 0.011114539348035525\n",
      "f([0.89761505 0.78790576]) = 0.011275402470144028\n"
     ]
    }
   ],
   "source": [
    "h_i = 0.1\n",
    "# Iteration 37\n",
    "with open(os.path.join(DATA_DIR, \"ex2_a.txt\"), mode='w') as f:\n",
    "    result = steepest_descent(func, gradient, h_i, x_start, partial(stop, error=0.01), write_to=f)\n",
    "    print(f\"f({result}) = {func(result)}\")\n",
    "\n",
    "h_i = 0.01\n",
    "with open(os.path.join(DATA_DIR, \"ex2_b.txt\"), mode='w') as f:\n",
    "    result = steepest_descent(func, gradient, h_i, x_start, partial(stop, error=0.001), write_to=f)\n",
    "    print(f\"f({result}) = {func(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(np.array([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 58\n",
      "         Function evaluations: 109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3379829250198353e-10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy_min = fmin(func, x0=x_start)\n",
    "func(scipy_min)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W porównaniu z metodą zmiennokrokową, w metodzie stałokrokowej nie wykonujemy dodatkowych obliczeń, więc możemy więcej iteracji zrobić"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_steepest_descent(func, gradient, learning_rate, start_point, stop_condition, write_to=None):\n",
    "    current_point = start_point\n",
    "    i = 1\n",
    "    while True:\n",
    "        print(f\"ITERATION {i}\", file=write_to)\n",
    "        gradient_value = gradient(current_point)\n",
    "        print(f\"\\tgradient_value = {gradient_value}\", file=write_to)\n",
    "        step_size = learning_rate(current_point, gradient_value, write_to) * gradient_value\n",
    "        print(f\"\\tstep_size = {step_size}\", file=write_to)\n",
    "        next_point = current_point - step_size \n",
    "        print(f\"\\tnext_point = {next_point}\", file=write_to)\n",
    "        print(f\"\\tf({next_point}) = {func(next_point)}\", file=write_to)\n",
    "\n",
    "        if stop_condition(current_point, next_point, write_to=write_to):\n",
    "            print(f\"Reached stop condition at {next_point}, value = {func(next_point):.2f}\", file=write_to)\n",
    "            break \n",
    "        i += 1\n",
    "        current_point = next_point\n",
    "    \n",
    "\n",
    "    return current_point\n",
    "\n",
    "\n",
    "def update_learning_rate(X, gradient, write_to=None):\n",
    "    \n",
    "    def metric(alpha):\n",
    "        # This is original function\n",
    "        return np.sum((X - alpha * gradient) ** 2)\n",
    "    \n",
    "    min_alpha = fmin(metric, x0=0.01, disp=False)\n",
    "    print(f\"\\talpha = {min_alpha[0]:.2f}\", file=write_to)\n",
    "    return min_alpha[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W metodzie zmiennokrokowej wykonujemy optymalizację kierunkową współczynnika kroku. Tutaj wybieramy takie $\\alpha$, by minimalizowało funkcję wejściową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\talpha = 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5000000000000007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_learning_rate(np.array([4, 4]), np.array([8, 8]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj potrzebowaliśmy jednego kroku, by znaleźć minimum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f([-5.32907052e-15 -5.32907052e-15]) = 5.679798517591285e-29\n"
     ]
    }
   ],
   "source": [
    "def func(X):\n",
    "    return np.sum(X ** 2)\n",
    "\n",
    "def gradient(X):\n",
    "    return X * 2\n",
    "\n",
    "x_start = np.array([4, 4])\n",
    "with open(os.path.join(DATA_DIR, \"ex3.txt\"), mode='w') as f:\n",
    "    result = var_steepest_descent(func, gradient, update_learning_rate, x_start, partial(stop, error=0.01), write_to=f)\n",
    "    print(f\"f({result}) = {func(result)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "def var_steepest_descent_2(func, gradient, learning_rate, start_point, stop_condition, write_to=None,\n",
    "                           max_iter=1000):\n",
    "    current_point = start_point\n",
    "    i = 1\n",
    "    while True:\n",
    "        print(f\"ITERATION {i}\", file=write_to)\n",
    "        gradient_value = gradient(current_point)\n",
    "        print(f\"\\tgradient_value = {gradient_value}\", file=write_to)\n",
    "        step_size = learning_rate(i, write_to) * gradient_value\n",
    "        print(f\"\\tstep_size = {step_size}\", file=write_to)\n",
    "        next_point = current_point - step_size \n",
    "        points.append(next_point)\n",
    "        print(f\"\\tnext_point = {next_point}\", file=write_to)\n",
    "        print(f\"\\tf({next_point}) = {func(next_point)}\", file=write_to)\n",
    "\n",
    "        if stop_condition(current_point, next_point, write_to=write_to) or i == max_iter:\n",
    "            print(f\"Reached stop condition at {next_point}, value = {func(next_point):.2f}\", file=write_to)\n",
    "            break \n",
    "        i += 1\n",
    "        current_point = next_point\n",
    "    \n",
    "\n",
    "    return current_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr1(i, write_to=None):\n",
    "    next_step = 0.0007 * i \n",
    "    print(f\"\\tnext step = {next_step:.2f}\", file=write_to)\n",
    "    return next_step\n",
    "\n",
    "def lr2(i, write_to=None):\n",
    "    next_step = 0.000701 * i \n",
    "    print(f\"\\tnext step = {next_step:.2f}\", file=write_to)\n",
    "    return next_step\n",
    "\n",
    "def lr3(i, write_to=None):\n",
    "    next_step = 0.03 * np.sqrt(i) \n",
    "    print(f\"\\tnext step = {next_step:.2f}\", file=write_to)\n",
    "    return next_step\n",
    "\n",
    "def lr4(i, write_to=None):\n",
    "    next_step = 0.03* np.power(i, 1 / 4)\n",
    "    print(f\"\\tnext step = {next_step:.2f}\", file=write_to)\n",
    "    return next_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a]: f([0.99054452 0.97963282]) = 9.537848629279827e-05\n",
      "[b]: f([0.99059457 0.9797404 ]) = 9.436956874481766e-05\n",
      "[d]: f([0.9889871  0.97629347]) = 0.00012940214379883423\n"
     ]
    }
   ],
   "source": [
    "methods = [lr1, lr2, lr4]\n",
    "names = ['a', 'b', 'd']\n",
    "\n",
    "def func(X):\n",
    "    return 2.5 * (X[0] ** 2 - X[1]) ** 2 + (1 - X[0]) ** 2\n",
    "\n",
    "def gradient(X):\n",
    "    return np.array([10 * X[0] ** 3 - 10 * X[0] * X[1] + 2 * X[0] - 2, \n",
    "                     -5 * (X[0] ** 2 - X[1])])\n",
    "\n",
    "\n",
    "x_start = np.array([-0.5, 1])\n",
    "\n",
    "for method, name in zip(methods, names):\n",
    "    with open(os.path.join(DATA_DIR, f\"ex4{name}.txt\"), mode='w') as f:\n",
    "        result = var_steepest_descent_2(func, gradient, method, x_start, partial(stop, error=0.001), write_to=f)\n",
    "        print(f\"[{name}]: f({result}) = {func(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9984\\4056960687.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.5 * (X[0] ** 2 - X[1]) ** 2 + (1 - X[0]) ** 2\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9984\\2746051287.py:34: RuntimeWarning: overflow encountered in square\n",
      "  return np.sqrt(np.sum(X ** 2))\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9984\\4056960687.py:8: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return np.array([10 * X[0] ** 3 - 10 * X[0] * X[1] + 2 * X[0] - 2,\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9984\\4056960687.py:9: RuntimeWarning: overflow encountered in double_scalars\n",
      "  -5 * (X[0] ** 2 - X[1])])\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9984\\4056960687.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 2.5 * (X[0] ** 2 - X[1]) ** 2 + (1 - X[0]) ** 2\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9984\\4056960687.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.array([10 * X[0] ** 3 - 10 * X[0] * X[1] + 2 * X[0] - 2,\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9984\\4056960687.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  -5 * (X[0] ** 2 - X[1])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[d]: f([nan nan]) = nan\n"
     ]
    }
   ],
   "source": [
    "x_start = np.array([-0.5, 1])\n",
    "\n",
    "with open(os.path.join(DATA_DIR, f\"ex4_c.txt\"), mode='w') as f:\n",
    "    result = var_steepest_descent_2(func, gradient, lr3, x_start, partial(stop, error=0.001), write_to=f,\n",
    "                                        max_iter=300)\n",
    "    print(f\"[{name}]: f({result}) = {func(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(points)\n",
    "points = np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25f2e231d20>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "n_points = 33\n",
    "\n",
    "plt.plot(points[:n_points, 0], points[:n_points, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataCampTutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
